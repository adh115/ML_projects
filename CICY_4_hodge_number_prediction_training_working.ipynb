{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to take the data instances as strings and convert them into a tuple that can be easily manipulated by the model. If matrix_output is True the Q matrix is output as a 2d array (matrix), otherwise it's output as a 1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_value(data_value, matrix_output = True):\n",
    "    import numpy as np\n",
    "    \n",
    "    y = data_value.split('{{', 1)\n",
    "    a, b = y[0].split('{')[1], y[1].split('}}', 1)\n",
    "    x = a.split(',')[:-1]\n",
    "    z = b[1].split(',')[1: -1]\n",
    "    q = b[0].replace('}', '').replace('{', '').split(',')\n",
    "    for i in range(len(x)):\n",
    "        x[i] = int(x[i])\n",
    "    for i in range(len(z)):\n",
    "        if i != 1 and z[i] != 'Null':\n",
    "            z[i] = int(z[i])\n",
    "    for i in range(len(q)):\n",
    "        q[i] = int(q[i])\n",
    "    if x[1] == z[2]: # is manifold favourable\n",
    "        z.append('True')\n",
    "    else:\n",
    "        if z[2] != 'Null':\n",
    "            z.append('False')\n",
    "        else:\n",
    "            z.append('Null')\n",
    "    if matrix_output:\n",
    "        q = np.array(q).reshape((x[1], x[2])) \n",
    "    else:\n",
    "        q = np.array(q)       \n",
    "    return x, q, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pair of functions to read in the data instances from the appropriate file and then process them. In the first case all of the information on each instance is retained, with the Q matrix being a 2d array if matrix_output is True and a 1d array otherwise. In the second function only the Q matrix (given as a 2d array if matrix_output = True, or a 1d array otherwise) and a single Hodge number (of the users' choice) are returned as a tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_instances(file_path, matrix_output = True):\n",
    "    import numpy as np\n",
    "    instances = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        line = f.readlines(1)\n",
    "        while line != []:\n",
    "            example = process_data_value(line[0], matrix_output)\n",
    "            instances.append(example)\n",
    "            line = f.readlines(1)\n",
    "    return np.array(instances, dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X_Y_instances(file_path, X_index, Y_index, matrix_output = True):\n",
    "    import numpy as np\n",
    "    X, Y = [], []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        line = f.readlines(1)\n",
    "        while line != []:\n",
    "            example = process_data_value(line[0], matrix_output)\n",
    "            X.append(example[X_index])\n",
    "            Y.append(example[-1][Y_index])\n",
    "            line = f.readlines(1)\n",
    "    return np.array(X, dtype = object), np.array(Y, dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to load the instances in a given file, pad them and return Q matrices and labels in a form that can directly be used in a model (since the shape of X is of form (number_instances, rows, columns))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_padded_X_Y_instances(file_path, X_index, Y_index, desired_shape, padding = 0, matrix_output = True):\n",
    "    import numpy as np\n",
    "    X_prime, Y = [], [] \n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        line = f.readlines(1)\n",
    "        while line != []:\n",
    "            example = process_data_value(line[0], matrix_output)\n",
    "            X_prime.append(example[X_index])\n",
    "            Y.append(example[-1][Y_index])\n",
    "            line = f.readlines(1)\n",
    "            \n",
    "    X = np.full((len(X_prime), desired_shape[0], desired_shape[1]), padding)\n",
    "    i = 0\n",
    "    for q_matrix in X_prime:\n",
    "        X[i, :, :] = pad_q_matrix(desired_shape = desired_shape, q_matrix = q_matrix, padding = 0)\n",
    "        i += 1\n",
    "    \n",
    "    return X, np.array(Y, dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to pad a Q matrix, given in 2d array form, to a desired shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_q_matrix(desired_shape, q_matrix, padding = 0):\n",
    "    import numpy as np\n",
    "    m, K = q_matrix.shape[0], q_matrix.shape[1]\n",
    "    q_tilde = np.full(desired_shape, padding)\n",
    "    j = 0\n",
    "    for i in range(m):\n",
    "        for j in range(K):\n",
    "            q_tilde[i, j] = q_matrix[i, j]\n",
    "    return q_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, validation, test data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the train, validation and test sets from the appropriate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_padded_X_Y_instances('./data/CICY_4_train.txt', 1, 2, desired_shape = (16, 20))\n",
    "X_val, Y_val = load_padded_X_Y_instances('./data/CICY_4_validation.txt', 1, 2, desired_shape = (16, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135852, 16, 20), (135852,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45284, 16, 20), (45284,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for h<sup>1,1</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [16, 20]),\n",
    "    keras.layers.Dense(units = 512, activation = 'sigmoid'),\n",
    "    keras.layers.Dropout(rate = 0.4),\n",
    "    keras.layers.Dense(units = 256, activation = 'sigmoid'),\n",
    "    keras.layers.Dropout(rate = 0.3),\n",
    "    keras.layers.Dense(units = 256, activation = 'sigmoid'),\n",
    "    keras.layers.Dense(units = 24, activation = 'softmax')\n",
    "])\n",
    "\n",
    "classifier_model.compile(loss = 'mse', optimizer = keras.optimizers.Adam(learning_rate = 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 106.2179\n",
      "Epoch 2/10\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 106.2177\n",
      "Epoch 3/10\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 106.2178\n",
      "Epoch 4/10\n",
      "4246/4246 [==============================] - 15s 3ms/step - loss: 106.2179\n",
      "Epoch 5/10\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 106.2178\n",
      "Epoch 6/10\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 106.2178\n",
      "Epoch 7/10\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 106.2177\n",
      "Epoch 8/10\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 106.2178\n",
      "Epoch 9/10\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 106.2178\n",
      "Epoch 10/10\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 106.2178\n"
     ]
    }
   ],
   "source": [
    "history = classifier_model.fit(X_train, Y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue now obvious, softmax outputs numbers in \\[0,1\\] whilst the targets are integers from 0 to 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model_v2 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [16, 20]),\n",
    "    keras.layers.Dense(units = 512, activation = 'relu'),\n",
    "    keras.layers.Dropout(rate = 0.4),\n",
    "    keras.layers.Dense(units = 256, activation = 'relu'),\n",
    "    keras.layers.Dropout(rate = 0.3),\n",
    "    keras.layers.Dense(units = 256, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 25, activation = 'softmax')\n",
    "])\n",
    "\n",
    "classifier_model_v2.compile(loss = 'sparse_categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate = 1/ 300), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 1.2168 - accuracy: 0.6057 - val_loss: 1.0323 - val_accuracy: 0.6568\n",
      "Epoch 2/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 1.0717 - accuracy: 0.6493 - val_loss: 0.9413 - val_accuracy: 0.6876\n",
      "Epoch 3/150\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 1.0105 - accuracy: 0.6711 - val_loss: 0.8751 - val_accuracy: 0.7189\n",
      "Epoch 4/150\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 0.9649 - accuracy: 0.6882 - val_loss: 0.8317 - val_accuracy: 0.7297\n",
      "Epoch 5/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 0.9276 - accuracy: 0.7015 - val_loss: 0.7894 - val_accuracy: 0.7444\n",
      "Epoch 6/150\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 0.8967 - accuracy: 0.7161 - val_loss: 0.7626 - val_accuracy: 0.7603\n",
      "Epoch 7/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 0.8693 - accuracy: 0.7265 - val_loss: 0.7226 - val_accuracy: 0.7675\n",
      "Epoch 8/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 0.8416 - accuracy: 0.7360 - val_loss: 0.7074 - val_accuracy: 0.7826\n",
      "Epoch 9/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 0.8169 - accuracy: 0.7450 - val_loss: 0.6785 - val_accuracy: 0.7835\n",
      "Epoch 10/150\n",
      "4246/4246 [==============================] - 13s 3ms/step - loss: 0.7985 - accuracy: 0.7547 - val_loss: 0.6618 - val_accuracy: 0.7961\n",
      "Epoch 11/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 0.7819 - accuracy: 0.7605 - val_loss: 0.6351 - val_accuracy: 0.8010\n",
      "Epoch 12/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 0.7621 - accuracy: 0.7666 - val_loss: 0.6164 - val_accuracy: 0.8093\n",
      "Epoch 13/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 0.7546 - accuracy: 0.7715 - val_loss: 0.5960 - val_accuracy: 0.8207\n",
      "Epoch 14/150\n",
      "4246/4246 [==============================] - 14s 3ms/step - loss: 0.7395 - accuracy: 0.7763 - val_loss: 0.6035 - val_accuracy: 0.8183\n",
      "Epoch 15/150\n",
      "4246/4246 [==============================] - 11s 3ms/step - loss: 0.7312 - accuracy: 0.7814 - val_loss: 0.5796 - val_accuracy: 0.8241\n",
      "Epoch 16/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.7215 - accuracy: 0.7845 - val_loss: 0.5606 - val_accuracy: 0.8307\n",
      "Epoch 17/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.7109 - accuracy: 0.7902 - val_loss: 0.5582 - val_accuracy: 0.8359\n",
      "Epoch 18/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6943 - accuracy: 0.7941 - val_loss: 0.5539 - val_accuracy: 0.8341\n",
      "Epoch 19/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6990 - accuracy: 0.7963 - val_loss: 0.5416 - val_accuracy: 0.8398\n",
      "Epoch 20/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6842 - accuracy: 0.7996 - val_loss: 0.5352 - val_accuracy: 0.8420\n",
      "Epoch 21/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6778 - accuracy: 0.8031 - val_loss: 0.5533 - val_accuracy: 0.8278\n",
      "Epoch 22/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6699 - accuracy: 0.8053 - val_loss: 0.5265 - val_accuracy: 0.8480\n",
      "Epoch 23/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6650 - accuracy: 0.8084 - val_loss: 0.5183 - val_accuracy: 0.8486\n",
      "Epoch 24/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6594 - accuracy: 0.8105 - val_loss: 0.5090 - val_accuracy: 0.8547\n",
      "Epoch 25/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6591 - accuracy: 0.8118 - val_loss: 0.4924 - val_accuracy: 0.8591\n",
      "Epoch 26/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6563 - accuracy: 0.8149 - val_loss: 0.5033 - val_accuracy: 0.8531\n",
      "Epoch 27/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6452 - accuracy: 0.8167 - val_loss: 0.4849 - val_accuracy: 0.8602\n",
      "Epoch 28/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6336 - accuracy: 0.8199 - val_loss: 0.4971 - val_accuracy: 0.8573\n",
      "Epoch 29/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6364 - accuracy: 0.8207 - val_loss: 0.4900 - val_accuracy: 0.8617\n",
      "Epoch 30/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6266 - accuracy: 0.8226 - val_loss: 0.4725 - val_accuracy: 0.8633\n",
      "Epoch 31/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6206 - accuracy: 0.8250 - val_loss: 0.4763 - val_accuracy: 0.8644\n",
      "Epoch 32/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6282 - accuracy: 0.8251 - val_loss: 0.4765 - val_accuracy: 0.8651\n",
      "Epoch 33/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6189 - accuracy: 0.8263 - val_loss: 0.4718 - val_accuracy: 0.8660\n",
      "Epoch 34/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6148 - accuracy: 0.8270 - val_loss: 0.4793 - val_accuracy: 0.8709\n",
      "Epoch 35/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6106 - accuracy: 0.8292 - val_loss: 0.4884 - val_accuracy: 0.8621\n",
      "Epoch 36/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6066 - accuracy: 0.8311 - val_loss: 0.4571 - val_accuracy: 0.8726\n",
      "Epoch 37/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6033 - accuracy: 0.8326 - val_loss: 0.4809 - val_accuracy: 0.8667\n",
      "Epoch 38/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6072 - accuracy: 0.8321 - val_loss: 0.4561 - val_accuracy: 0.8729\n",
      "Epoch 39/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.6007 - accuracy: 0.8346 - val_loss: 0.4598 - val_accuracy: 0.8719\n",
      "Epoch 40/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5925 - accuracy: 0.8345 - val_loss: 0.4486 - val_accuracy: 0.8753\n",
      "Epoch 41/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5904 - accuracy: 0.8369 - val_loss: 0.4561 - val_accuracy: 0.8749\n",
      "Epoch 42/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5947 - accuracy: 0.8383 - val_loss: 0.4504 - val_accuracy: 0.8747\n",
      "Epoch 43/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5859 - accuracy: 0.8388 - val_loss: 0.4462 - val_accuracy: 0.8761\n",
      "Epoch 44/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5832 - accuracy: 0.8401 - val_loss: 0.4439 - val_accuracy: 0.8789\n",
      "Epoch 45/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5783 - accuracy: 0.8404 - val_loss: 0.4374 - val_accuracy: 0.8792\n",
      "Epoch 46/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5781 - accuracy: 0.8413 - val_loss: 0.4514 - val_accuracy: 0.8810\n",
      "Epoch 47/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5827 - accuracy: 0.8419 - val_loss: 0.4275 - val_accuracy: 0.8827\n",
      "Epoch 48/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5783 - accuracy: 0.8418 - val_loss: 0.4406 - val_accuracy: 0.8764\n",
      "Epoch 49/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5725 - accuracy: 0.8441 - val_loss: 0.4408 - val_accuracy: 0.8807\n",
      "Epoch 50/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5751 - accuracy: 0.8448 - val_loss: 0.4344 - val_accuracy: 0.8812\n",
      "Epoch 51/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5728 - accuracy: 0.8448 - val_loss: 0.4316 - val_accuracy: 0.8841\n",
      "Epoch 52/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5682 - accuracy: 0.8445 - val_loss: 0.4431 - val_accuracy: 0.8841\n",
      "Epoch 53/150\n",
      "4246/4246 [==============================] - 11s 3ms/step - loss: 0.5654 - accuracy: 0.8476 - val_loss: 0.4293 - val_accuracy: 0.8815\n",
      "Epoch 54/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5663 - accuracy: 0.8477 - val_loss: 0.4391 - val_accuracy: 0.8810\n",
      "Epoch 55/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5609 - accuracy: 0.8476 - val_loss: 0.4278 - val_accuracy: 0.8857\n",
      "Epoch 56/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5755 - accuracy: 0.8476 - val_loss: 0.4351 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5614 - accuracy: 0.8473 - val_loss: 0.4341 - val_accuracy: 0.8839\n",
      "Epoch 58/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5645 - accuracy: 0.8490 - val_loss: 0.4182 - val_accuracy: 0.8878\n",
      "Epoch 59/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5563 - accuracy: 0.8494 - val_loss: 0.4297 - val_accuracy: 0.8873\n",
      "Epoch 60/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5676 - accuracy: 0.8501 - val_loss: 0.4515 - val_accuracy: 0.8824\n",
      "Epoch 61/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5560 - accuracy: 0.8523 - val_loss: 0.4162 - val_accuracy: 0.8897\n",
      "Epoch 62/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5535 - accuracy: 0.8511 - val_loss: 0.4141 - val_accuracy: 0.8912\n",
      "Epoch 63/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5608 - accuracy: 0.8522 - val_loss: 0.4288 - val_accuracy: 0.8877\n",
      "Epoch 64/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5551 - accuracy: 0.8525 - val_loss: 0.4116 - val_accuracy: 0.8877\n",
      "Epoch 65/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5467 - accuracy: 0.8533 - val_loss: 0.4254 - val_accuracy: 0.8830\n",
      "Epoch 66/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5451 - accuracy: 0.8547 - val_loss: 0.4293 - val_accuracy: 0.8880\n",
      "Epoch 67/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5651 - accuracy: 0.8538 - val_loss: 0.4089 - val_accuracy: 0.8906\n",
      "Epoch 68/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5513 - accuracy: 0.8545 - val_loss: 0.4161 - val_accuracy: 0.8880\n",
      "Epoch 69/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5494 - accuracy: 0.8557 - val_loss: 0.4205 - val_accuracy: 0.8895\n",
      "Epoch 70/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5541 - accuracy: 0.8548 - val_loss: 0.4354 - val_accuracy: 0.8870\n",
      "Epoch 71/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5635 - accuracy: 0.8552 - val_loss: 0.4022 - val_accuracy: 0.8905\n",
      "Epoch 72/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5474 - accuracy: 0.8559 - val_loss: 0.4046 - val_accuracy: 0.8929\n",
      "Epoch 73/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5463 - accuracy: 0.8563 - val_loss: 0.4165 - val_accuracy: 0.8899\n",
      "Epoch 74/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5509 - accuracy: 0.8560 - val_loss: 0.4046 - val_accuracy: 0.8945\n",
      "Epoch 75/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5518 - accuracy: 0.8575 - val_loss: 0.4354 - val_accuracy: 0.8899\n",
      "Epoch 76/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5566 - accuracy: 0.8574 - val_loss: 0.4107 - val_accuracy: 0.8892\n",
      "Epoch 77/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5508 - accuracy: 0.8558 - val_loss: 0.3997 - val_accuracy: 0.8926\n",
      "Epoch 78/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5364 - accuracy: 0.8596 - val_loss: 0.4097 - val_accuracy: 0.8899\n",
      "Epoch 79/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5366 - accuracy: 0.8581 - val_loss: 0.4183 - val_accuracy: 0.8903\n",
      "Epoch 80/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5347 - accuracy: 0.8586 - val_loss: 0.4109 - val_accuracy: 0.8892\n",
      "Epoch 81/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5461 - accuracy: 0.8591 - val_loss: 0.4074 - val_accuracy: 0.8920\n",
      "Epoch 82/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5316 - accuracy: 0.8606 - val_loss: 0.4042 - val_accuracy: 0.8937\n",
      "Epoch 83/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5307 - accuracy: 0.8618 - val_loss: 0.4061 - val_accuracy: 0.8935\n",
      "Epoch 84/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5375 - accuracy: 0.8605 - val_loss: 0.3951 - val_accuracy: 0.8957\n",
      "Epoch 85/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5238 - accuracy: 0.8616 - val_loss: 0.4133 - val_accuracy: 0.8900\n",
      "Epoch 86/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5269 - accuracy: 0.8615 - val_loss: 0.4148 - val_accuracy: 0.8923\n",
      "Epoch 87/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5255 - accuracy: 0.8628 - val_loss: 0.4223 - val_accuracy: 0.8927\n",
      "Epoch 88/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5545 - accuracy: 0.8641 - val_loss: 0.3917 - val_accuracy: 0.8979\n",
      "Epoch 89/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5295 - accuracy: 0.8623 - val_loss: 0.4151 - val_accuracy: 0.8942\n",
      "Epoch 90/150\n",
      "4246/4246 [==============================] - 11s 3ms/step - loss: 0.5246 - accuracy: 0.8628 - val_loss: 0.4126 - val_accuracy: 0.8904\n",
      "Epoch 91/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5342 - accuracy: 0.8629 - val_loss: 0.4039 - val_accuracy: 0.8945\n",
      "Epoch 92/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5259 - accuracy: 0.8634 - val_loss: 0.4535 - val_accuracy: 0.8835\n",
      "Epoch 93/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5193 - accuracy: 0.8637 - val_loss: 0.3965 - val_accuracy: 0.8975\n",
      "Epoch 94/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5247 - accuracy: 0.8627 - val_loss: 0.3989 - val_accuracy: 0.8950\n",
      "Epoch 95/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5188 - accuracy: 0.8633 - val_loss: 0.4182 - val_accuracy: 0.8891\n",
      "Epoch 96/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5239 - accuracy: 0.8650 - val_loss: 0.4019 - val_accuracy: 0.8960\n",
      "Epoch 97/150\n",
      "4246/4246 [==============================] - 11s 3ms/step - loss: 0.5267 - accuracy: 0.8640 - val_loss: 0.3978 - val_accuracy: 0.8960\n",
      "Epoch 98/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5199 - accuracy: 0.8661 - val_loss: 0.4013 - val_accuracy: 0.8984\n",
      "Epoch 99/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5135 - accuracy: 0.8662 - val_loss: 0.3987 - val_accuracy: 0.8999\n",
      "Epoch 100/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5207 - accuracy: 0.8656 - val_loss: 0.3905 - val_accuracy: 0.8983\n",
      "Epoch 101/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5217 - accuracy: 0.8647 - val_loss: 0.3966 - val_accuracy: 0.8985\n",
      "Epoch 102/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5154 - accuracy: 0.8660 - val_loss: 0.3947 - val_accuracy: 0.8972\n",
      "Epoch 103/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5286 - accuracy: 0.8650 - val_loss: 0.3955 - val_accuracy: 0.8961\n",
      "Epoch 104/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5147 - accuracy: 0.8674 - val_loss: 0.3951 - val_accuracy: 0.8989\n",
      "Epoch 105/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5172 - accuracy: 0.8664 - val_loss: 0.3998 - val_accuracy: 0.8956\n",
      "Epoch 106/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5157 - accuracy: 0.8666 - val_loss: 0.3876 - val_accuracy: 0.8961\n",
      "Epoch 107/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5135 - accuracy: 0.8674 - val_loss: 0.4163 - val_accuracy: 0.8968\n",
      "Epoch 108/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5200 - accuracy: 0.8671 - val_loss: 0.3938 - val_accuracy: 0.9005\n",
      "Epoch 109/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5279 - accuracy: 0.8681 - val_loss: 0.3878 - val_accuracy: 0.9012\n",
      "Epoch 110/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5152 - accuracy: 0.8695 - val_loss: 0.3920 - val_accuracy: 0.9010\n",
      "Epoch 111/150\n",
      "4246/4246 [==============================] - 11s 3ms/step - loss: 0.5100 - accuracy: 0.8677 - val_loss: 0.3861 - val_accuracy: 0.9018\n",
      "Epoch 112/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5130 - accuracy: 0.8687 - val_loss: 0.3922 - val_accuracy: 0.9011\n",
      "Epoch 113/150\n",
      "4246/4246 [==============================] - 11s 3ms/step - loss: 0.5197 - accuracy: 0.8678 - val_loss: 0.3929 - val_accuracy: 0.8998\n",
      "Epoch 114/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5126 - accuracy: 0.8696 - val_loss: 0.4138 - val_accuracy: 0.8977\n",
      "Epoch 115/150\n",
      "4246/4246 [==============================] - 11s 3ms/step - loss: 0.5117 - accuracy: 0.8695 - val_loss: 0.4060 - val_accuracy: 0.8996\n",
      "Epoch 116/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5234 - accuracy: 0.8681 - val_loss: 0.3962 - val_accuracy: 0.8979\n",
      "Epoch 117/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5197 - accuracy: 0.8689 - val_loss: 0.4011 - val_accuracy: 0.8983\n",
      "Epoch 118/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5106 - accuracy: 0.8710 - val_loss: 0.3881 - val_accuracy: 0.9000\n",
      "Epoch 119/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5151 - accuracy: 0.8695 - val_loss: 0.3946 - val_accuracy: 0.8968\n",
      "Epoch 120/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5146 - accuracy: 0.8692 - val_loss: 0.4013 - val_accuracy: 0.8994\n",
      "Epoch 121/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5082 - accuracy: 0.8701 - val_loss: 0.3981 - val_accuracy: 0.8970\n",
      "Epoch 122/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5146 - accuracy: 0.8695 - val_loss: 0.3984 - val_accuracy: 0.9004\n",
      "Epoch 123/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5132 - accuracy: 0.8699 - val_loss: 0.3933 - val_accuracy: 0.9007\n",
      "Epoch 124/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5144 - accuracy: 0.8704 - val_loss: 0.3967 - val_accuracy: 0.9020\n",
      "Epoch 125/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5158 - accuracy: 0.8703 - val_loss: 0.3972 - val_accuracy: 0.9002\n",
      "Epoch 126/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5111 - accuracy: 0.8703 - val_loss: 0.3912 - val_accuracy: 0.9014\n",
      "Epoch 127/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5147 - accuracy: 0.8696 - val_loss: 0.4025 - val_accuracy: 0.9010\n",
      "Epoch 128/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5019 - accuracy: 0.8723 - val_loss: 0.4021 - val_accuracy: 0.9019\n",
      "Epoch 129/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5057 - accuracy: 0.8723 - val_loss: 0.3933 - val_accuracy: 0.9028\n",
      "Epoch 130/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5132 - accuracy: 0.8719 - val_loss: 0.3919 - val_accuracy: 0.8996\n",
      "Epoch 131/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5221 - accuracy: 0.8712 - val_loss: 0.3925 - val_accuracy: 0.9028\n",
      "Epoch 132/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.4964 - accuracy: 0.8726 - val_loss: 0.3978 - val_accuracy: 0.9010\n",
      "Epoch 133/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5103 - accuracy: 0.8709 - val_loss: 0.4029 - val_accuracy: 0.9016\n",
      "Epoch 134/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5121 - accuracy: 0.8720 - val_loss: 0.4094 - val_accuracy: 0.8987\n",
      "Epoch 135/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.4978 - accuracy: 0.8724 - val_loss: 0.4008 - val_accuracy: 0.9046\n",
      "Epoch 136/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5074 - accuracy: 0.8749 - val_loss: 0.4093 - val_accuracy: 0.8987\n",
      "Epoch 137/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5033 - accuracy: 0.8710 - val_loss: 0.3977 - val_accuracy: 0.9006\n",
      "Epoch 138/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5157 - accuracy: 0.8712 - val_loss: 0.3964 - val_accuracy: 0.9018\n",
      "Epoch 139/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5172 - accuracy: 0.8726 - val_loss: 0.3913 - val_accuracy: 0.9023\n",
      "Epoch 140/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5176 - accuracy: 0.8747 - val_loss: 0.4017 - val_accuracy: 0.9026\n",
      "Epoch 141/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5075 - accuracy: 0.8740 - val_loss: 0.3918 - val_accuracy: 0.9013\n",
      "Epoch 142/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.4931 - accuracy: 0.8732 - val_loss: 0.4001 - val_accuracy: 0.9047\n",
      "Epoch 143/150\n",
      "4246/4246 [==============================] - 11s 3ms/step - loss: 0.4998 - accuracy: 0.8738 - val_loss: 0.3965 - val_accuracy: 0.9025\n",
      "Epoch 144/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5019 - accuracy: 0.8732 - val_loss: 0.3932 - val_accuracy: 0.9035\n",
      "Epoch 145/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5034 - accuracy: 0.8747 - val_loss: 0.3968 - val_accuracy: 0.9025\n",
      "Epoch 146/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5125 - accuracy: 0.8726 - val_loss: 0.4080 - val_accuracy: 0.9018\n",
      "Epoch 147/150\n",
      "4246/4246 [==============================] - 11s 3ms/step - loss: 0.5060 - accuracy: 0.8752 - val_loss: 0.4026 - val_accuracy: 0.9028\n",
      "Epoch 148/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5267 - accuracy: 0.8745 - val_loss: 0.4067 - val_accuracy: 0.9036\n",
      "Epoch 149/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.5052 - accuracy: 0.8748 - val_loss: 0.3929 - val_accuracy: 0.9032\n",
      "Epoch 150/150\n",
      "4246/4246 [==============================] - 12s 3ms/step - loss: 0.4986 - accuracy: 0.8751 - val_loss: 0.3926 - val_accuracy: 0.9050\n"
     ]
    }
   ],
   "source": [
    "history = classifier_model_v2.fit(X_train, Y_train, epochs = 150,\n",
    "                                  validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.array([i for i in range(150)])\n",
    "plt.plot(epochs + 1/2, history.history['loss'], label = 'loss', color = 'b')\n",
    "plt.plot(epochs, history.history['val_loss'], label = 'val_loss', color = 'g')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model_v2.save('512_0.4_256_0.3_256_25_relu_softmax_cross_entropy_adam_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
